{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>HSE FCS SE ML</h1></center>\n",
    "<center><h1>\"Fast sold post prediction\" Kaggle competition</h1></center>\n",
    "<center><h2>Team name: Turbo 3D</h2></center>\n",
    "<center><h3>Daniil Kraynov, Dmitry Strokov, Danil Kolesnikov</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.tsv', sep='\\t').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \"properties\" feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_properties(jstr_orig):\n",
    "    jstr = jstr_orig\n",
    "    jstr = jstr.replace(\"\\\"Cee'd\\\"\", \"'_'\")\n",
    "    jstr = jstr.replace(\"\\\\xa0\", \"_\")\n",
    "    jstr = jstr.replace(\"\\\"Levi's\\\"\", \"'_'\")\n",
    "    jstr = jstr.replace(\"\\\"Victoria's Secret\\\"\", \"'_'\")\n",
    "    jstr = jstr.replace(\"\\\"O'Stin\\\"\", \"'_'\")\n",
    "    jstr = jstr.replace(\"\\\"Carter's\\\"\", \"'_'\")\n",
    "    jstr = jstr.replace(\"\\\"Colin's\\\"\", \"'_'\")\n",
    "    jstr = jstr.replace('\"', '!@#$').replace(\"'\", '\"').replace('!@#$', \"'\")\n",
    "    try:\n",
    "        obj = json.loads(jstr)\n",
    "        return obj\n",
    "    except:\n",
    "        print(jstr)\n",
    "    return json.loads(jstr)\n",
    "\n",
    "min_usage = 50\n",
    "\n",
    "def preprocess_properties(df_source):\n",
    "    s = df_source.drop(columns=['properties'])\n",
    "    \n",
    "    props_col = df_source['properties'].apply(parse_properties)\n",
    "    \n",
    "    all_props = dict()\n",
    "    for props in props_col.values:\n",
    "        for prop in props:\n",
    "            prop_name = \"slug_\" + prop['slug_id'] \n",
    "            if prop_name not in all_props:\n",
    "                all_props[prop_name] = 0\n",
    "            all_props[prop_name] += 1\n",
    "    \n",
    "    for i in range(len(s)):\n",
    "        if i % 20000 == 0:\n",
    "            print(\"Done: {:.2f}%\".format(i / len(s) * 100))\n",
    "        for prop in props_col.values[i]:\n",
    "            prop_name = \"slug_\" + prop['slug_id']\n",
    "            if all_props[prop_name] < min_usage:\n",
    "                continue\n",
    "            if prop_name not in s.columns:\n",
    "                s[prop_name] = -1\n",
    "            s.at[i, prop_name] = prop[\"value_id\"]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = preprocess_properties(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study/preprocess categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to understand what categories are important before applying one-hot encoding to categorical features.\n",
    "\n",
    "We asume that category importancy depends on usage (number of entries) and sold probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_sold_probability(df_source, column, value):\n",
    "    target_col = df_source['sold_fast'].values\n",
    "    target_col_in_category = target_col[column == value]\n",
    "    target_col_in_category_sold = target_col_in_category[target_col_in_category == 1]\n",
    "    return len(target_col_in_category_sold) / len(target_col_in_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's consider magnitude as abs(sold_probability - 0.5)\n",
    "def get_category_magnitude(df_source, column, value):\n",
    "    return abs(get_category_sold_probability(df_source, column, value) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = []\n",
    "\n",
    "min_usage = 50\n",
    "\n",
    "except_columns = ['date_created', 'delivery_available', 'payment_available',\n",
    "                  'img_num', 'lat', 'long', 'price', 'product_id', 'sold_fast']\n",
    "\n",
    "for i in range(len(df2.columns)):\n",
    "    feature_name = df2.columns[i]\n",
    "    if feature_name in except_columns:\n",
    "        print(\"\\rSkipping\", feature_name, \"[\", i + 1, \"of\", len(df2.columns), \"]\", \" \" * 100, end='')\n",
    "        continue\n",
    "    print(\"\\rScanning\", feature_name, \"[\", i + 1, \"of\", len(df2.columns), \"]\", \" \" * 100, end='')\n",
    "    column = df2[feature_name].values\n",
    "    categories, usages = np.unique(column, return_counts=True)\n",
    "    for i in range(len(categories)):\n",
    "        usage = usages[i]\n",
    "        if usage < min_usage:\n",
    "            continue\n",
    "        category = categories[i]\n",
    "        if \"slug\" in feature_name and category == -1:\n",
    "            continue\n",
    "        info = [feature_name, category]\n",
    "        info.append(usage)\n",
    "        info.append(\"{:.3f}%\".format(usage / len(column) * 100))\n",
    "        info.append(get_category_magnitude(df2, column, category))\n",
    "        all_categories.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_categories = set()\n",
    "\n",
    "def select_top_categories(from_cat, n_select):\n",
    "    global selected_categories\n",
    "    top_features = from_cat['feature'].values[:n_select]\n",
    "    top_categories = from_cat['category'].values[:n_select]\n",
    "    selected_categories |= set(zip(top_features, top_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = pd.DataFrame(\n",
    "    np.array(all_categories),\n",
    "    columns=['feature', 'category', 'usage', 'usage%', 'magnitude']\n",
    ")\n",
    "for col_name in ['usage', 'magnitude']:\n",
    "    cat_df[col_name] = pd.to_numeric(cat_df[col_name])\n",
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select some categories with highest magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_by_magnitude = cat_df.sort_values(by=['magnitude'], ascending=False)\n",
    "cat_df_by_magnitude.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_top_categories(cat_df_by_magnitude, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_by_usage = cat_df.sort_values(by=['usage'], ascending=False)\n",
    "cat_df_by_usage.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_top_categories(cat_df_by_usage, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Encode data to numberable format\n",
    "# Drop excess columns\n",
    "# Apply one hot encoding\n",
    "def encode_data(df_source):\n",
    "    lb = LabelEncoder()\n",
    "    \n",
    "    columns_to_drop = ['product_id']\n",
    "    for col_name in df_source.columns:\n",
    "        if 'slug' in col_name:\n",
    "            columns_to_drop.append(col_name)\n",
    "    \n",
    "    s = df_source.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Delivery/payment encoding: 0 is false (bad), 1 is true (good)\n",
    "    s['delivery_available'] = lb.fit_transform(s['delivery_available'])\n",
    "    s['payment_available'] = lb.fit_transform(s['payment_available'])\n",
    "    # City/region encoding\n",
    "    s['city'] = lb.fit_transform(s['city'])\n",
    "    s['region'] = lb.fit_transform(s['region'])\n",
    "    # Converting date to timestamp\n",
    "    dates = s['date_created'].values\n",
    "    convert_time = lambda d: int(time.mktime(datetime.datetime.strptime(d, \"%Y-%m-%d\").timetuple()))\n",
    "    s['date_created'] = list(map(convert_time, dates))\n",
    "    # Misc\n",
    "    s['owner_id'] = lb.fit_transform(s['owner_id'])\n",
    "    \n",
    "    s['name_text'] = s['name_text'].apply(len)\n",
    "    s['desc_text'] = s['desc_text'].apply(len)\n",
    "    \n",
    "    for feature, category in selected_categories:\n",
    "        fcol = df_source[feature].apply(str).values\n",
    "        ncol = np.zeros(len(fcol), dtype='int64')\n",
    "        ncol[fcol == category] = 1\n",
    "        s['{}={}'.format(feature, category)] = ncol\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = encode_data(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(columns=['sold_fast'])\n",
    "y = df_encoded['sold_fast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting & Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid kernel dying\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# from matplotlib.pylab import rcParams\n",
    "# rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "# def modelfit(alg, Xt, yt, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "#     if useTrainCV:\n",
    "#         xgb_param = alg.get_xgb_params()\n",
    "#         xgtrain = xgb.DMatrix(Xt, label=yt)\n",
    "#         cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "#             metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "#         alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "#     #Fit the algorithm on the data\n",
    "#     alg.fit(Xt, yt, eval_metric='auc')\n",
    "        \n",
    "#     #Predict training set:\n",
    "#     dtrain_predictions = alg.predict(Xt)\n",
    "#     dtrain_predprob = alg.predict_proba(Xt)[:,1]\n",
    "        \n",
    "#     #Print model report:\n",
    "#     print(\"\\nModel Report\")\n",
    "#     print(\"Accuracy : %.4g\" % metrics.accuracy_score(yt, dtrain_predictions))\n",
    "#     print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(yt, dtrain_predprob))\n",
    "                    \n",
    "#     feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def do_gridsearch(static_params, search_params):\n",
    "#     gsearch = GridSearchCV(\n",
    "#         estimator = XGBClassifier(**static_params),\n",
    "#         param_grid = search_params,\n",
    "#         scoring='roc_auc',\n",
    "#         n_jobs=4,\n",
    "#         iid=False,\n",
    "#         cv=5,\n",
    "#         verbose=3\n",
    "#     )\n",
    "#     gsearch.fit(X, y)\n",
    "#     return gsearch.best_params_, gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgb_params = {\n",
    "#     'base_score': 0.5,\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'colsample_bylevel': 1,\n",
    "#     'gamma': 0.46,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'n_estimators': 444,\n",
    "#     'max_depth': 4,\n",
    "#     'min_child_weight': 4,\n",
    "#     'max_delta_step': 0,\n",
    "#     'missing': None,\n",
    "#     'reg_alpha': 0,\n",
    "#     'reg_lambda': 1,\n",
    "#     'scale_pos_weight': 1,\n",
    "#     'seed': 27,\n",
    "#     'silent': 1,\n",
    "#     'subsample': 0.95,\n",
    "#     'colsample_bytree': 0.8,\n",
    "#     'nthread': 4,\n",
    "#     'n_jobs': 4\n",
    "# }\n",
    "\n",
    "# search_params = {\n",
    "#     'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100]\n",
    "# }\n",
    "\n",
    "# #bp, bs = do_gridsearch(xgb_params, search_params)\n",
    "# #bp, bs\n",
    "\n",
    "# xgbm = XGBClassifier(**xgb_params)\n",
    "# modelfit(xgbm, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# model = XGBClassifier(**xgb_params)\n",
    "\n",
    "# cross_val_score(model, X, y, cv=5, scoring='roc_auc', verbose=3, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# model = XGBClassifier()\n",
    "# cross_val_score(model, X, y, cv=3, scoring='roc_auc', verbose=3, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'gamma': 0,\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 5000, # Set best before real fit/predict!!!\n",
    "    'max_depth': 6,\n",
    "    'seed': 27,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'n_jobs': 4\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(**xgb_params)\n",
    "#0.639196\n",
    "#783 n_est\n",
    "xgb.cv(\n",
    "    model.get_xgb_params(),\n",
    "    xgb.DMatrix(X, label=y),\n",
    "    num_boost_round=xgb_params['n_estimators'],\n",
    "    nfold=3,\n",
    "    metrics='auc',\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_nolabel.tsv', sep='\\t').drop(columns='Unnamed: 0')\n",
    "df_test[\"sold_fast\"] = 0\n",
    "df_merged = pd.concat([df, df_test])\n",
    "df_merged.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_p = encode_data(preprocess_properties(df_merged))\n",
    "df_mp = df_merged_p[:len(df)]\n",
    "df_test_mp = df_merged_p[len(df):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit = df_mp.drop(columns=['sold_fast'])\n",
    "y_fit = df_mp['sold_fast']\n",
    "X_actual = df_test_mp.drop(columns=['sold_fast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(**xgb_params)\n",
    "model.fit(X_fit, y_fit)\n",
    "y_actual = model.predict_proba(X_actual)[:, 1]\n",
    "y_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame.from_dict({'product_id' : df_test['product_id'].values, 'score' : y_actual})\n",
    "df_final.to_csv('submission.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
